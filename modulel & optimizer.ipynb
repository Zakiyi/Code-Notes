{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "模型参数检索\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "##### 模型定义\n",
    "##### 也可以直接使用 nn.functional 来定义网络层， 但是这种情况下该层参数并不会自动添加到模型 modules\n",
    "class Simple_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Simple_net, self).__init__()\n",
    "        \n",
    "        self.conv0 = nn.Conv2d(10, 20, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn0 = nn.BatchNorm2d(20)\n",
    "        self.relu0 = nn.PReLU()    \n",
    "        \n",
    "        self.conv1 = nn.Conv2d(20, 10, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(10)\n",
    "        self.relu1 = nn.PReLU()\n",
    "        \n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(10, 2)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        output = self.relu0(self.bn0(self.conv0(inputs)))\n",
    "        output = self.relu1(self.bn1(self.conv1(output)))\n",
    "        output = self.fc(self.pool(output))\n",
    "        \n",
    "        return torch.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化模型同时构建优化器\n",
    "model = Simple_net()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters list len:  12\n",
      "first layer parameter:  torch.Size([20, 10, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# 模型 parameters 列表\n",
    "para_list = list(model.parameters())                            # conv/fc 2; bn 1 \n",
    "print('parameters list len: ', len(para_list))\n",
    "print('first layer parameter: ', para_list[0].shape)            # 卷积层参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "named parameters list len:  12\n",
      "first layer param name:  conv0.weight\n",
      "first layer param data:  Parameter containing:\n",
      "tensor([[[[-0.0184, -0.0313, -0.0406],\n",
      "          [-0.0637, -0.0931,  0.0688],\n",
      "          [-0.0218,  0.0254, -0.0662]],\n",
      "\n",
      "         [[ 0.0099,  0.0565,  0.0633],\n",
      "          [-0.0497,  0.0920,  0.0997],\n",
      "          [ 0.0769,  0.0816, -0.0015]],\n",
      "\n",
      "         [[ 0.0769,  0.0079,  0.0538],\n",
      "          [ 0.0684, -0.0090,  0.0540],\n",
      "          [ 0.0089, -0.0913, -0.0649]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0548, -0.0925,  0.0547],\n",
      "          [-0.0083,  0.0603,  0.1018],\n",
      "          [-0.0979, -0.0870,  0.0337]],\n",
      "\n",
      "         [[-0.0712, -0.0302,  0.0966],\n",
      "          [-0.0753,  0.0535, -0.1005],\n",
      "          [ 0.0768,  0.0238, -0.0316]],\n",
      "\n",
      "         [[-0.0633,  0.0743, -0.0443],\n",
      "          [-0.0498, -0.0297, -0.0362],\n",
      "          [ 0.0323,  0.0489, -0.0007]]],\n",
      "\n",
      "\n",
      "        [[[-0.0138, -0.0691, -0.0992],\n",
      "          [-0.0615,  0.0617, -0.0417],\n",
      "          [-0.0045, -0.0429, -0.0068]],\n",
      "\n",
      "         [[ 0.0704, -0.0688, -0.0525],\n",
      "          [ 0.0326, -0.0013,  0.0196],\n",
      "          [ 0.0627, -0.0412, -0.0618]],\n",
      "\n",
      "         [[ 0.0232, -0.0813, -0.0675],\n",
      "          [ 0.0530, -0.0192,  0.0385],\n",
      "          [-0.0228,  0.0038,  0.0107]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0999,  0.0784,  0.0848],\n",
      "          [ 0.0521, -0.0373,  0.0800],\n",
      "          [ 0.0396, -0.0617,  0.0441]],\n",
      "\n",
      "         [[-0.0878, -0.0181, -0.0016],\n",
      "          [ 0.0113,  0.0736,  0.0692],\n",
      "          [-0.0029,  0.0354,  0.0082]],\n",
      "\n",
      "         [[ 0.0484, -0.0905,  0.0468],\n",
      "          [-0.0572,  0.0729, -0.0209],\n",
      "          [ 0.0203,  0.0680,  0.0807]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0217,  0.0480, -0.0094],\n",
      "          [-0.0514, -0.0121, -0.0399],\n",
      "          [-0.0419, -0.0713, -0.0117]],\n",
      "\n",
      "         [[-0.0866, -0.0392, -0.0324],\n",
      "          [ 0.0757, -0.1035, -0.0104],\n",
      "          [ 0.0915,  0.0025, -0.0454]],\n",
      "\n",
      "         [[-0.0620,  0.0007,  0.0385],\n",
      "          [ 0.0372, -0.0160,  0.0176],\n",
      "          [ 0.0749, -0.0153,  0.0906]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1041, -0.0830,  0.0193],\n",
      "          [ 0.0258, -0.0047,  0.0197],\n",
      "          [ 0.0606, -0.0811, -0.0079]],\n",
      "\n",
      "         [[ 0.0356, -0.0031, -0.0431],\n",
      "          [-0.0011,  0.0757,  0.0933],\n",
      "          [ 0.0155, -0.0309,  0.0329]],\n",
      "\n",
      "         [[ 0.0505, -0.0174, -0.0151],\n",
      "          [-0.0477,  0.0581,  0.0293],\n",
      "          [ 0.0297,  0.0015,  0.0703]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0544, -0.0482,  0.0485],\n",
      "          [ 0.0843, -0.0748,  0.0206],\n",
      "          [ 0.0127,  0.0751, -0.0401]],\n",
      "\n",
      "         [[-0.0051,  0.0581, -0.0399],\n",
      "          [ 0.0733, -0.0638, -0.0848],\n",
      "          [-0.0970, -0.0561,  0.0515]],\n",
      "\n",
      "         [[ 0.0342,  0.0314,  0.0892],\n",
      "          [-0.0397, -0.0273,  0.0594],\n",
      "          [-0.0499, -0.0010, -0.0895]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0237,  0.0803, -0.0441],\n",
      "          [ 0.0229, -0.0056, -0.0464],\n",
      "          [ 0.0503, -0.0695,  0.0791]],\n",
      "\n",
      "         [[ 0.0392,  0.0870, -0.1029],\n",
      "          [ 0.1033, -0.0170,  0.0535],\n",
      "          [-0.0939, -0.0767,  0.1036]],\n",
      "\n",
      "         [[-0.1014, -0.0232, -0.0471],\n",
      "          [ 0.0866,  0.0182,  0.0849],\n",
      "          [ 0.0997, -0.0460, -0.0625]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0946, -0.0071, -0.0381],\n",
      "          [-0.0452, -0.0911, -0.0354],\n",
      "          [-0.0767,  0.0142, -0.0967]],\n",
      "\n",
      "         [[ 0.0217,  0.0897, -0.0283],\n",
      "          [ 0.0266,  0.0683,  0.0459],\n",
      "          [ 0.0174, -0.0336, -0.0130]],\n",
      "\n",
      "         [[ 0.0146, -0.0245, -0.0124],\n",
      "          [-0.0416,  0.0083, -0.0568],\n",
      "          [-0.0728,  0.0878,  0.0253]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0831,  0.0528,  0.0147],\n",
      "          [ 0.0353,  0.0903,  0.1042],\n",
      "          [ 0.0032, -0.0651,  0.0647]],\n",
      "\n",
      "         [[-0.0083, -0.1029,  0.0722],\n",
      "          [ 0.0810,  0.0100, -0.0503],\n",
      "          [-0.1048, -0.0878,  0.0258]],\n",
      "\n",
      "         [[-0.0551,  0.0573,  0.0233],\n",
      "          [-0.0112, -0.0667,  0.0461],\n",
      "          [ 0.0952,  0.0205, -0.0353]]],\n",
      "\n",
      "\n",
      "        [[[-0.0642,  0.0722,  0.0728],\n",
      "          [-0.0460,  0.0759, -0.0979],\n",
      "          [ 0.0068, -0.0150,  0.0386]],\n",
      "\n",
      "         [[ 0.0517,  0.0955, -0.0807],\n",
      "          [ 0.0557,  0.0377, -0.0761],\n",
      "          [-0.0387, -0.0014, -0.0725]],\n",
      "\n",
      "         [[-0.0279, -0.0764, -0.0038],\n",
      "          [-0.0583, -0.0797,  0.0347],\n",
      "          [-0.0060,  0.0020, -0.0379]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0529,  0.0023,  0.0673],\n",
      "          [ 0.0350,  0.0838,  0.0374],\n",
      "          [-0.0331, -0.0172, -0.0094]],\n",
      "\n",
      "         [[-0.0492, -0.0743, -0.0381],\n",
      "          [-0.0643,  0.0670,  0.0707],\n",
      "          [-0.0541, -0.0765, -0.0175]],\n",
      "\n",
      "         [[ 0.0229, -0.0292,  0.0855],\n",
      "          [-0.0084, -0.0280,  0.0079],\n",
      "          [-0.0749,  0.0580, -0.0937]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 模型 named parameters 列表\n",
    "named_para_list = list(model.named_parameters())\n",
    "first_layer_para_name = named_para_list[0][0]            # conv0 name --> conv0.weight\n",
    "first_layer_para_data = named_para_list[0][1]            # conv0 weight --> tensor\n",
    "\n",
    "print('named parameters list len: ', len(named_para_list))\n",
    "print('first layer param name: ', first_layer_para_name)\n",
    "print('first layer param data: ', first_layer_para_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "modules list len:  9\n",
      "first module:  Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "first_layer param number:  2  weights:  torch.Size([20, 10, 3, 3])  bias:  torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "# 模型 modules 列表\n",
    "# type(model.conv0) == nn.Conv2d\n",
    "module_list = list(model.modules())\n",
    "print('modules list len: ', len(module_list))\n",
    "\n",
    "# 第一层卷积层\n",
    "print('first module: ', module_list[1])\n",
    "\n",
    "first_layer_param = list(module_list[1].parameters())   # 第一层卷积层参数， conv有两项参数，weight + bias\n",
    "print('first_layer param number: ', len(first_layer_param),\n",
    "      ' weights: ', first_layer_param[0].shape, \n",
    "      ' bias: ', first_layer_param[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "named_list len:  9\n",
      "first named module:  ('conv0', Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n",
      "first layer name:  conv0\n",
      "first layer module:  Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "first layer module para:  torch.Size([20, 10, 3, 3]) torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "# 模型 named modules 列表\n",
    "named_module_list = list(model.named_modules())\n",
    "print('named_list len: ', len(named_module_list))\n",
    "\n",
    "# 第一层卷积\n",
    "print('first named module: ', named_module_list[1])\n",
    "\n",
    "first_layer_name = named_module_list[1][0]\n",
    "first_layer_module = named_module_list[1][1]\n",
    "first_layer_module_param = list(first_layer_module.parameters())\n",
    "print('first layer name: ', first_layer_name)\n",
    "print('first layer module: ', first_layer_module)\n",
    "print('first layer module para: ', first_layer_module_param[0].shape, first_layer_module_param[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv0.weight              value shape:  torch.Size([20, 10, 3, 3])\n",
      "conv0.bias              value shape:  torch.Size([20])\n",
      "bn0.weight              value shape:  torch.Size([20])\n",
      "bn0.bias              value shape:  torch.Size([20])\n",
      "bn0.running_mean              value shape:  torch.Size([20])\n",
      "bn0.running_var              value shape:  torch.Size([20])\n",
      "bn0.num_batches_tracked              value shape:  torch.Size([])\n",
      "relu0.weight              value shape:  torch.Size([1])\n",
      "conv1.weight              value shape:  torch.Size([10, 20, 3, 3])\n",
      "conv1.bias              value shape:  torch.Size([10])\n",
      "bn1.weight              value shape:  torch.Size([10])\n",
      "bn1.bias              value shape:  torch.Size([10])\n",
      "bn1.running_mean              value shape:  torch.Size([10])\n",
      "bn1.running_var              value shape:  torch.Size([10])\n",
      "bn1.num_batches_tracked              value shape:  torch.Size([])\n",
      "relu1.weight              value shape:  torch.Size([1])\n",
      "fc.weight              value shape:  torch.Size([2, 10])\n",
      "fc.bias              value shape:  torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# 模型 state dict\n",
    "model_state_dict = model.state_dict()\n",
    "for key, value in model_state_dict.items():\n",
    "    print(key, '             value shape: ', value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 10, 3, 3])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict['conv0.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=10, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "初始化网络参数\n",
    "model.apply(fn), 对网络中间层进行参数初始化\n",
    "\"\"\"\n",
    "net = nn.Sequential(nn.Linear(10, 2))\n",
    "def init_weight(layer):\n",
    "    if type(layer) == nn.Linear:\n",
    "        layer.weight.data.fill_(1.0)\n",
    "\n",
    "net.apply(init_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "torch 模型保存有两种方式（https://pytorch.org/docs/master/notes/serialization.html#recommend-saving-models）\n",
    "第一种：只保存模型参数（state_dict）， 官方比较推荐这一种方式\n",
    "第二种：保存整个模型\n",
    "\n",
    "直接保存整个模型的话，其存储数据结构被限定特定格式，不利于后续的模型加载重用，比如当模型定义类发生变化时，加载模型可能会出问题\n",
    "\"\"\"\n",
    "\n",
    "#第一种：只保存模型参数\n",
    "torch.save(model.state_dict(), save_path)  # save model\n",
    "model = Model_class(**args)                # construct new model\n",
    "model = model.load_state_dict(torch.load(save_path))  # load saved parameters to the model\n",
    "\n",
    "#第二种：保存整个模型\n",
    "torch.save(model, save_path)     # save the entire model\n",
    "model = torch.load(save_path)    # load the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "optimizer通过param_group来管理参数组.param_group中保存了参数组及其对应的学习率,动量等等.\n",
    "所以我们可以通过更改param_group[‘lr’]的值来更改对应参数组的学习率。\n",
    "'''\n",
    "# 学习率衰减\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = args.lr * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
