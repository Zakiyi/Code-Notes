{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(simple_net, self).__init__()\n",
    "        \n",
    "        self.conv0 = nn.Conv2d(10, 20, 3, 1)\n",
    "        self.bn = nn.BatchNorm2d(20)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(20, 20, 3, 1)\n",
    "    \n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self.module, name)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        output = self.relu(self.bn(self.conv0(inputs)))\n",
    "        output = self.conv1(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simple_net()\n",
    "model.to(\"cuda\")\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'a'), (2, 'b'), (3, 'c')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a = [1,2,3]\n",
    "b = ['a', 'b', 'c']\n",
    "list(map(lambda x,y: (x, y), a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter(lambda x: )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Separable_conv(nn.Module):\n",
    "    \"\"\"\n",
    "    3x3 depth-wise conv + 1x1 point-wise conv\n",
    "    3x3 depth-wise conv --> [bn, relu](optional) --> 1x1 point-wise conv --> bn\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channel, out_channel=None, kernel=3, stride=1, padding=1, dilation=1, is_bn=False, bias=False):\n",
    "        super(Separable_conv, self).__init__()\n",
    "        self.is_bn = is_bn\n",
    "\n",
    "        if out_channel is None:\n",
    "            out_channel = in_channel\n",
    "\n",
    "        self.depthwise_conv = nn.Conv2d(in_channel, in_channel, kernel_size=kernel, stride=stride, padding=padding,\n",
    "                                        dilation=dilation, groups=in_channel, bias=bias)\n",
    "        if self.is_bn:\n",
    "            self.bn = nn.BatchNorm2d(in_channel)\n",
    "            self.act = nn.PReLU()\n",
    "\n",
    "        self.pointwise_conv = nn.Conv2d(in_channel, out_channel, kernel_size=1, stride=1, padding=0, bias=bias)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        output = self.depthwise_conv(inputs)\n",
    "\n",
    "        if self.is_bn:\n",
    "            output = self.act(self.bn(output))\n",
    "\n",
    "        output = self.pointwise_conv(output)\n",
    "\n",
    "        return output\n",
    "    \n",
    "class SE_block(nn.Module):\n",
    "    def __init__(self, in_channel, ratio=2, is_dropout=False, block_type='scSE'):\n",
    "        \"\"\"\n",
    "        :param in_channel:\n",
    "        :param ratio:\n",
    "        :param block_type: 'scSE', 'sSE', 'cSE'\n",
    "        https://arxiv.org/pdf/1808.08127.pdf\n",
    "        https://github.com/ai-med/squeeze_and_excitation/blob/master/squeeze_and_excitation/squeeze_and_excitation.py\n",
    "        \"\"\"\n",
    "        super(SE_block, self).__init__()\n",
    "        assert block_type in ('scSE', 'sSE', 'cSE')\n",
    "\n",
    "        self.type = block_type\n",
    "        self.is_dropout = is_dropout\n",
    "        self.channel_se = False if self.type == 'sSE' else True\n",
    "        self.spatial_se = False if self.type == 'cSE' else True\n",
    "\n",
    "        # spatial squeeze & channel excitation\n",
    "        if self.channel_se:\n",
    "            out_channel = in_channel//ratio\n",
    "            self.cse_fc0 = nn.Linear(in_channel, out_channel)\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "            self.cse_fc1 = nn.Linear(out_channel, in_channel)\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # channel squeeze\n",
    "        if self.spatial_se:\n",
    "            self.sse_conv = nn.Conv2d(in_channel, 1, kernel_size=1, stride=1)\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        if self.is_dropout:\n",
    "            self.dropout = nn.Dropout2d(0.2)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        batch_size, num_channels, H, W = inputs.size()\n",
    "        output = inputs\n",
    "\n",
    "        if self.channel_se:\n",
    "            output_cse = inputs.view(batch_size, num_channels, -1).mean(dim=2)   # global average\n",
    "            output_cse = self.relu(self.cse_fc0(output_cse))     # fc --> relu\n",
    "            output_cse = self.sigmoid(self.cse_fc1(output_cse))  # fc --> sigmoid\n",
    "\n",
    "            # channel-wise multiple\n",
    "            output_cse = torch.mul(inputs, output_cse.view(batch_size, num_channels, 1, 1))\n",
    "            output = output_cse\n",
    "\n",
    "        if self.spatial_se:\n",
    "            output_sse = self.sigmoid(self.sse_conv(inputs))     # conv --> sigmoid\n",
    "\n",
    "            # spatially multiple\n",
    "            output_sse = torch.mul(inputs, output_sse.view(batch_size, 1, H, W))\n",
    "            output = output_sse\n",
    "\n",
    "        if self.type == 'scSE':\n",
    "            # otuput = output_cse + output_sse\n",
    "            output = torch.max(output_cse, output_sse)\n",
    "\n",
    "        if self.is_dropout:\n",
    "            output = self.dropout(output)\n",
    "\n",
    "        return output\n",
    "    \n",
    "class Transition_Up(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel=None):\n",
    "        super(Transition_Up, self).__init__()\n",
    "        if out_channel is None:\n",
    "            out_channel = in_channel\n",
    "\n",
    "        self.out_channel = out_channel\n",
    "        self.trans_conv = nn.ConvTranspose2d(in_channel, out_channel,\n",
    "                                             kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        output = self.trans_conv(inputs)\n",
    "\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Decoder_Dense(nn.Module):\n",
    "    def __init__(self, in_channel, encode_in, out_channel, is_dropout=True):\n",
    "        super(Decoder_Dense, self).__init__()\n",
    "        self.is_dropout = is_dropout\n",
    "        self.trans_up = Transition_Up(in_channel, encode_in)\n",
    "        if self.is_dropout:\n",
    "            self.dropout = nn.Dropout2d(0.2)\n",
    "\n",
    "        self.depthwise_conv = nn.Sequential(nn.BatchNorm2d(2*encode_in),\n",
    "                                            nn.PReLU(),\n",
    "                                            Separable_conv(2*encode_in, out_channel, is_bn=True))\n",
    "\n",
    "        self.SE_block = SE_block(out_channel)\n",
    "\n",
    "    def forward(self, encode_in, up_in):\n",
    "        output = self.trans_up(up_in)\n",
    "        output = torch.cat([encode_in, output], dim=1)\n",
    "\n",
    "        if self.is_dropout:\n",
    "            output = self.dropout(output)\n",
    "\n",
    "        output = self.depthwise_conv(output)\n",
    "        output = self.SE_block(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Decoder_Dense(20, 10,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trans_up.trans_conv.weight\n",
      "trans_up.trans_conv.bias\n",
      "depthwise_conv.0.weight\n",
      "depthwise_conv.0.bias\n",
      "depthwise_conv.1.weight\n",
      "depthwise_conv.2.depthwise_conv.weight\n",
      "depthwise_conv.2.bn.weight\n",
      "depthwise_conv.2.bn.bias\n",
      "depthwise_conv.2.act.weight\n",
      "depthwise_conv.2.pointwise_conv.weight\n",
      "SE_block.cse_fc0.weight\n",
      "SE_block.cse_fc0.bias\n",
      "SE_block.cse_fc1.weight\n",
      "SE_block.cse_fc1.bias\n",
      "SE_block.sse_conv.weight\n",
      "SE_block.sse_conv.bias\n"
     ]
    }
   ],
   "source": [
    "for name, value in a.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
